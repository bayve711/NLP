{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill out the information of your group!\n",
    "\n",
    "| <p style=\"text-align: center;\">First Name</p> | <p style=\"text-align: center;\">Family Name</p> | Matr.-No. |\n",
    "|-----------------------------------------|-----------------------------------------| --- |\n",
    "| <p style=\"text-align: left\">*Daniil*</p>     | <p style=\"text-align: left\">*Krechko*</p>     | *k12149099* |\n",
    "| <p style=\"text-align: left\">*Azat*</p> | <p style=\"text-align: left\">*Vakhitov*</p> | *k12148222* |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\">344.105/6/7 UE: Natural Language Processing (WS2023/24)</h2>\n",
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 2</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\">Getting to Know Word Embedding!</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Terms of Use</b><br>\n",
    "This  material is prepared for educational purposes at the Johannes Kepler University (JKU) Linz, and is exclusively provided to the registered students of the mentioned course at JKU. It is strictly forbidden to distribute the current file, the contents of the assignment, and its solution. The use or reproduction of this manuscript is only allowed for educational purposes in non-profit organizations, while in this case, the explicit prior acceptance of the author(s) is required.\n",
    "\n",
    "**Authors:** Shah Nawaz, Shahed Masoudian<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of contents</h2>\n",
    "<ol>\n",
    "    <a href=\"#section-general-guidelines\"><li style=\"font-size:large;font-weight:bold\">General Guidelines</li></a>\n",
    "    <a href=\"#section-taskA\"><li style=\"font-size:large;font-weight:bold\">Task A: Words Similarity and Nearest Neighbors (15 points)</li></a>\n",
    "    <a href=\"#section-taskB\"><li style=\"font-size:large;font-weight:bold\">Task B: Document Classification with Word Embedding (15 points)</li></a>\n",
    "    <a href=\"#section-taskC\"><li style=\"font-size:large;font-weight:bold\">Task C: Classification with sent2vec Document Embeddings (2 extra point)</li></a>\n",
    "    <a href=\"#section-references\"><li style=\"font-size:large;font-weight:bold\">References</li></a>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-general-guidelines\"></a><h2 style=\"color:rgb(0,120,170)\">General Guidelines</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment objective\n",
    "The aim of this assignment is to get familiarized with using word embedding (WE) models in practice. The assignment in total has **30 points**; it also offers **2 extra points** which can cover any missing point.\n",
    "\n",
    "This Notebook encompasses all aspects of the assignment, namely the descriptions of tasks as well as your solutions and reports. Feel free to add any required cell for solutions. The cells can contain code, reports, charts, tables, or any other material, required for the assignment. Feel free to provide the solutions in an interactive and visual way! \n",
    "\n",
    "Please discuss any unclear point in the assignment in the provided forum in MOODLE. It is also encouraged to provide answers to your peer's questions. However when submitting a post, keep in mind to avoid providing solutions. Please let the tutor(s) know shall you find any error or unclarity in the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries & Dataset\n",
    "\n",
    "The assignment should be implemented with recent versions of `Python` (>3.7). Any standard Python library can be used, so far that the library is free and can be simply installed using `pip` or `conda`. Examples of potentially useful libraries are `scikit-learn`, `numpy`, `scipy`, `gensim`, `nltk`, `spaCy`, and `AllenNLP`. Use the latest stable version of each library.\n",
    "\n",
    "To conduct the experiments, we use a subset of the `HumSet` dataset [1] (https://blog.thedeep.io/humset/). `HumSet` is created by the DEEP (https://www.thedeep.io) project â€“ an open source platform which aims to facilitate processing of textual data for international humanitarian response organizations. The platform enables the classification of text excerpts, extracted from news and reports into a set of domain specific classes. The provided dataset contains the classes (labels) referring to the humanitarian sectors like agriculture, health, and protection. The dataset contains an overall number of 17,301 data points. \n",
    "\n",
    "Download the dataset from the Moodle page of the course.\n",
    "\n",
    "the provided zip file consists of the following files:\n",
    "- `thedeep.subset.train.txt`: Train set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.validation.txt`: Validation set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.test.txt`: Test set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.label.txt`: Captions of the labels.\n",
    "- `thedeep.ToU.txt`: Terms of use of the dataset.\n",
    "\n",
    "[1] HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crises Response\n",
    "*Selim Fekih, Nicolo' Tamagnone, Benjamin Minixhofer, Ranjan Shrestha, Ximena Contla, Ewan Oglethorpe and Navid Rekabsaz.* \n",
    "In Findings of the 2022 Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP), December 2022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style \n",
    "\n",
    "- Please provide evidence at each state by giving print of the results, provide tables, graphs to further improve the quality of your report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Submission\n",
    "\n",
    "Each group should submit the following two files:\n",
    "\n",
    "- One Jupyter Notebook file (`.ipynb`), containing all the code, results, visualizations, etc. **In the submitted Notebook, all the results and visualizations should already be present, and can be observed simply by loading the Notebook in a browser.** The Notebook must be self-contained, meaning that (if necessary) one can run all the cells from top to bottom without any error. Do not forget to put in your names and student numbers in the first cell of the Notebook. \n",
    "- The HTML file (`.html`) achieved from exporting the Jupyter Notebook to HTML (Download As HTML).\n",
    "\n",
    "You do not need to include the data files in the submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:23.606623Z",
     "start_time": "2024-12-08T23:40:22.898798Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:23.609135Z",
     "start_time": "2024-12-08T23:40:23.607529Z"
    }
   },
   "outputs": [],
   "source": [
    "PLOTS_SHOW = False\n",
    "WIN_PATHS_ENABLED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:23.621475Z",
     "start_time": "2024-12-08T23:40:23.609810Z"
    }
   },
   "outputs": [],
   "source": [
    "def full_vocabluary(data):\n",
    "    all_tokens = [token for doc in data['Text'] for token in doc]\n",
    "\n",
    "    token_counts = Counter(all_tokens)\n",
    "\n",
    "    vocab = dict(token_counts)\n",
    "    return vocab\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def preprocessing(data):\n",
    "    \n",
    "    pattern_2 = r'^\"|\"$'\n",
    "    data['Text'] = data['Text'].apply(lambda x: re.sub(pattern_2, '', x))\n",
    "    \n",
    "    pattern_3 = r'\\s+'\n",
    "    data['Text'] = data['Text'].apply(lambda x: re.sub(pattern_3, ' ', x))\n",
    "    \n",
    "    written_date_pattern = r'\\b(?:\\d{1,2}(?:st|nd|rd|th)?\\s*)?(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s*(?:\\d{1,2}(?:st|nd|rd|th)?)?\\s*(?:\\d{4})?\\b'\n",
    "    data['Text'] = data['Text'].apply(lambda x: re.sub(written_date_pattern, '|date| ', x))\n",
    "    \n",
    "    percent_pattern = r'\\b\\d+(?:\\s*(?:percent|per\\s*cent|%))\\b'\n",
    "    number_pattern = r'\\b(?:\\d{1,3}(?:[\\.,\\s]?\\d{3})*(?:[\\.,]?\\d+)?(?:\\s*(?:hundred|thousand|million|billion|trillion|k|K|m|M))?|\\d+(?:\\.\\d+)?(?:\\s*(?:kg|g|lbs|cm|m|km|ft|in))?)\\b'\n",
    "    percent_patter_0 = r'.*%'\n",
    "    \n",
    "    data['Text'] = data['Text'].apply(lambda x: re.sub(percent_pattern, '|num| ', x))\n",
    "    data['Text'] = data['Text'].apply(lambda x: re.sub(number_pattern, '|num| ', x))\n",
    "    data['Text'] = data['Text'].apply(lambda x: re.sub(percent_patter_0, '', x))\n",
    "    \n",
    "    # Remove marks\n",
    "    marks_pattern = r'[^\\w\\s|]'\n",
    "    data['Text'] = data['Text'].apply(lambda x: re.sub(marks_pattern, ' ', x))\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    data['Text'] = data['Text'].apply(lambda x: x.lower())\n",
    "    data['Text'] = data['Text'].apply(remove_stop_words)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    data['Text'] = data['Text'].apply(lambda x: re.sub(pattern_3, ' ', x))\n",
    "    \n",
    "    # Tokenize and lemmatize\n",
    "    words = data['Text'].apply(word_tokenize)\n",
    "    tagged_words = words.apply(pos_tag)\n",
    "    data['Text'] = tagged_words.apply(lemmatize)\n",
    "    \n",
    "    # Replace |num| and |date| back to <num> and <date>\n",
    "    data['Text'] = data['Text'].apply(lambda tokens: [token.replace('|num|', '<num>').replace('|date|', '<date>') for token in tokens])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('NN'):\n",
    "        return 'n'  # noun\n",
    "    elif tag.startswith('VB'):\n",
    "        return 'v'  # verb\n",
    "    elif tag.startswith('JJ'):\n",
    "        return 'a'  # adjective\n",
    "    elif tag.startswith('RB'):\n",
    "        return 'r'  # adverb\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize(tagged_sentence):\n",
    "    lemmatized_words = []\n",
    "    for word, tag in tagged_sentence:\n",
    "        wordnet_pos = get_wordnet_pos(tag)\n",
    "    \n",
    "        if wordnet_pos is None:\n",
    "            wordnet_pos = 'n'\n",
    "    \n",
    "        lemmatized_word = lemmatizer.lemmatize(word, wordnet_pos)\n",
    "    \n",
    "        lemmatized_words.append(lemmatized_word)\n",
    "    return lemmatized_words\n",
    "\n",
    "\n",
    "def token_statistics(vocab):\n",
    "    filtered_vocab_1 = {token: count for token, count in vocab.items() if token not in {'<num>', '<date>'}}\n",
    "    \n",
    "    counts = list(filtered_vocab_1.values())\n",
    "    mean_1 = np.mean(counts)\n",
    "    max_count_1 = np.max(counts)\n",
    "    min_count_1 = np.min(counts)\n",
    "    std_dev_1 = np.std(counts)\n",
    "\n",
    "    return mean_1, max_count_1, min_count_1, std_dev_1\n",
    "\n",
    "def filter_vocab(vocab, min_freq):\n",
    "    filtered_vocab = {token: count for token, count in vocab.items() if count >= min_freq}\n",
    "    return filtered_vocab\n",
    "\n",
    "\n",
    "def replace_with_oov(data, vocab):\n",
    "    return [[token if token in vocab else '<OOV>' for token in doc] for doc in data['Text']]\n",
    "\n",
    "def replace_with_oov_avoid(data, vocab):\n",
    "    return [[token if token in vocab else token for token in doc] for doc in data['Text']]\n",
    "\n",
    "def token_statistics_after(vocab_filtered):\n",
    "    filtered_vocab_2 = {token: count for token, count in vocab_filtered.items() if token not in {'<num>', '<date>'}}\n",
    "    \n",
    "    counts = list(filtered_vocab_2.values())  \n",
    "    mean_2 = np.mean(counts)\n",
    "    max_count_2 = np.max(counts)\n",
    "    min_count_2 = np.min(counts)\n",
    "    std_dev_2 = np.std(counts)\n",
    "\n",
    "    return mean_2, max_count_2, min_count_2, std_dev_2\n",
    "\n",
    "def calculate_document_frequencies(data, word_to_index):\n",
    "    df = np.zeros(vocab_size, dtype=int)\n",
    "    for doc in data:\n",
    "        unique_terms = set(doc)\n",
    "        for term in unique_terms:\n",
    "            if term in word_to_index:\n",
    "                index = word_to_index[term]\n",
    "                df[index] += 1\n",
    "    return df\n",
    "\n",
    "def compute_tfidf_vectors(data, word_to_index, df, N):\n",
    "    idf = np.log(N / (df + 1))\n",
    "\n",
    "    vectors = []\n",
    "    for doc in data:\n",
    "        vector = np.zeros(vocab_size)\n",
    "        term_counts = Counter(doc)\n",
    "        for term, count in term_counts.items():\n",
    "            if term in word_to_index:\n",
    "                index = word_to_index[term]\n",
    "                tf = count \n",
    "                vector[index] = tf * idf[index]\n",
    "        vectors.append(vector)\n",
    "    return vectors\n",
    "\n",
    "#Sparsity rate\n",
    "def calculate_sparsity(vectors):\n",
    "    total_elements = 0\n",
    "    zero_elements = 0\n",
    "    for vector in vectors:\n",
    "        total_elements += len(vector)\n",
    "        zero_elements += np.count_nonzero(vector == 0)\n",
    "    sparsity_rate = (zero_elements / total_elements) * 100\n",
    "    return sparsity_rate\n",
    "\n",
    "        \n",
    "def analyze_word_contributions_by_category(data, category_column, text_column):\n",
    "    word_category_counts = {}\n",
    "    category_totals = {}\n",
    "    for _, row in data.iterrows():\n",
    "        category = row[category_column]\n",
    "        words = row[text_column]\n",
    "        if category not in word_category_counts:\n",
    "            word_category_counts[category] = Counter()\n",
    "        word_category_counts[category].update(words)\n",
    "        \n",
    "        if category not in category_totals:\n",
    "            category_totals[category] = 0\n",
    "        category_totals[category] += len(words)\n",
    "\n",
    "    word_contributions = {}\n",
    "    for category, counter in word_category_counts.items():\n",
    "        total = category_totals[category]\n",
    "        word_contributions[category] = {word: count / total for word, count in counter.items()}\n",
    "\n",
    "    return word_contributions \n",
    "\n",
    "def plot_word_contributions(word_contributions, category, top_n=10):\n",
    "    words, contributions = zip(*sorted(word_contributions[category].items(), key=lambda item: item[1], reverse=True)[:top_n])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(words, contributions, color='skyblue')\n",
    "    plt.xlabel('Word Contribution')\n",
    "    plt.title(f'Top {top_n} Word Contributions in Category: {category}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "def plot_similarity(word, nearest_neighbors, metric):\n",
    "    neighbors, similarities = zip(*nearest_neighbors)  \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(neighbors, similarities, color=\"skyblue\")\n",
    "    plt.xlabel(f\"{metric} Similarity\")\n",
    "    plt.ylabel(\"Nearest Neighbors\")\n",
    "    plt.title(f\"{metric} Similarity for Word: '{word}'\")\n",
    "    plt.gca().invert_yaxis() \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Calculate nearest neighbors\n",
    "def calculate_nearest_neighbours(source_words, target_words, model, k, cosine: bool, dot: bool):\n",
    "    # Get source embeddings (n_source, embedding_dim)\n",
    "    source_embeddings = np.array([model[word] for word in source_words])  \n",
    "\n",
    "    # Get target embeddings (n_target, embedding_dim)\n",
    "    target_embeddings = np.array([model[word] for word in target_words])  \n",
    "\n",
    "    results = {}\n",
    "\n",
    "    if cosine:\n",
    "        # Normalize both source and target embeddings\n",
    "        source_norms = np.linalg.norm(source_embeddings, axis=1, keepdims=True)  # (n_source, 1)\n",
    "        target_norms = np.linalg.norm(target_embeddings, axis=1, keepdims=True)  # (n_target, 1)\n",
    "\n",
    "        source_embeddings = source_embeddings / source_norms  # Normalize source embeddings\n",
    "        target_embeddings = target_embeddings / target_norms  # Normalize target embeddings\n",
    "\n",
    "        # Compute cosine similarity for all sources against all targets\n",
    "        similarity_matrix = np.dot(source_embeddings, target_embeddings.T)  # (n_source, n_target)\n",
    "    elif dot:\n",
    "        similarity_matrix = np.dot(source_embeddings, target_embeddings.T)  # (n_source, n_target)\n",
    "    else:\n",
    "        raise ValueError(\"Please specify a similarity metric (cosine or dot).\")\n",
    "    \n",
    "    # Extract top-k neighbors for each source word\n",
    "    for i, source_word in enumerate(source_words):\n",
    "        # Get top-k indices and scores (sorted in descending order)\n",
    "        top_k_indices = np.argsort(-similarity_matrix[i])[:k]  # Negative for descending sort\n",
    "        top_k_words = [(target_words[idx], similarity_matrix[i][idx]) for idx in top_k_indices]\n",
    "        results[source_word] = dict(top_k_words)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_vocab(data):\n",
    "    all_tokens = [word for doc in data['Text'] for word in doc]\n",
    "    return dict(Counter(all_tokens))\n",
    "\n",
    "\n",
    "def compute_document_embeddings(data, word_embeddings, embedding_dim=300):\n",
    "    document_embeddings = []\n",
    "    for doc in data['Text']:\n",
    "        embeddings = [word_embeddings[word] for word in doc if word in word_embeddings]\n",
    "        if embeddings:\n",
    "            doc_embedding = np.mean(embeddings, axis=0)\n",
    "        else:\n",
    "            doc_embedding = np.zeros(embedding_dim)\n",
    "        document_embeddings.append(doc_embedding)\n",
    "    return np.array(document_embeddings)\n",
    "\n",
    "\n",
    "def map_word_embeddings(vocab, model, embedding_dim=300):\n",
    "    embeddings = {}\n",
    "    for word in vocab:\n",
    "        if word in model:\n",
    "            embeddings[word] = model[word]\n",
    "        else:\n",
    "            embeddings[word] = np.random.uniform(-0.1, 0.1, embedding_dim)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-taskA\"></a><h2 style=\"color:rgb(0,120,170)\">Task A: Words Similarity and Nearest Neighbors (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Loading a word embedding (WE) model (1 points).** Download a pre-trained word embedding model such as word2vec (https://code.google.com/archive/p/word2vec/) or GloVe (https://nlp.stanford.edu/projects/glove/). You can load the downloaded vectors into arrays, or use libraries such as `gensim` to download and process the vectors. \n",
    "\n",
    "**Calculating word-to-word similarities (4 points).** Select <ins>5 arbitrary words</ins> from 5 different topics like objects, science disciplines, verbs, adjectives, animals, etc. Let us refer to these words as *source words*. For each source word, calculate its cosine similarities to <ins>6 target words</ins>. The target words of each source word are also selected by you and should cover various levels of semantic relations â€“ according to your linguistic judgement â€“ to the source word, namely from highly-related to not related at all. Organize the target words in tables, such that the target words of each source word are sorted from the highest to the lowest relevance (according to your judgement). Consider the following points:\n",
    "\n",
    "- **Implementation (2/4 points):** Implement cosine similarity as a function that takes two vectors and returns the similarity score. Implement cosine by yourself and do NOT use the provided functionalities of any library.\n",
    "- **Reporting and observations (2/4 points):** Report the calculated similarities side by side with your word-to-word semantic relevance judgements in tables. Compare the results and report your observations.  \n",
    "\n",
    "**Calculating nearest neighbors (10 points).** For the 5 source words, retrieve the $k=10$ nearest neighbors using the word embedding model, namely the words with the highest similarities to the source word. Consider the following points: \n",
    "    \n",
    "- **Overall implementation (3/10 points):** your implemented function takes a source vector, a set of target vectors, and the $k$ parameter, and returns the $k$ nearest neighbors and their similarity scores. Implement nearest neighbor calculation by yourself and do NOT use the provided functionalities of any library.\n",
    "- **Similarity metrics (2/10 points):** execute the calculation of nearest neighbors according to <ins>two similarity metrics</ins> namely cosine and dot product.\n",
    "- **Efficiency (3/10 points):** your nearest neighbor functions should provide an *efficient* calculation of nearest neighbors. An inefficient way (which should be avoided!) would be looping over the set of vectors in the word embedding model, and one by one calculating the cosine/dot product similarity of the source vector to each of the target vectors. As a hint for an efficient way, consider that in `numpy` (and other libraries), calculating the dot product of a vector to a matrix is much faster than the dot products of the vector to each vector of the matrix.\n",
    "- **Reporting and observations (2/10 points):** report the results in tables, which enable comparing between the outputs of the two similarity metrics. Which similarity metric would you prefer? Report your observations.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:23.843528Z",
     "start_time": "2024-12-08T23:40:23.622732Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\azatv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\azatv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\azatv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\azatv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\azatv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\azatv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') \n",
    "\n",
    "stop_words = {\n",
    "    'the', 'a', 'and', 'to', 'be', 'in', 'that', 'of', 'for', 'on', 'with', 'at', 'by', 'an', 'this',\n",
    "    'it', 'is', 'was', 'from', 'or', 'but', 'are', 'we', 'can', 'you', 'all', 'have', 'which',\n",
    "    'there', 'their', 'they', 'who', 'about', 'were', 'had', 'has', 'will', 'my', 'your', 'more', 'if',\n",
    "    'do', 'does', 'theirs', 'how', 'all', 'any', 'some', 'than', 'then', 'been', 'being',\n",
    "    'i', 'me', 'us', 'he', 'she', 'him', 'her', 'ours', 'yours', 'ourselves', 'yourself', 'yourselves', \n",
    "    'himself', 'herself', 'itself', 'ours', 'those', 'such', 'same', 'so', 'up', 'down', 'where', \n",
    "    'when', 'out', 'just', 'over', 'after', 'before', 'once', 'during', 'also', 'because', 'now', \n",
    "    'off', 'here', 'one', 'each', 'both', 'either', 'every', 'other', 'again', 'between', 'few', \n",
    "    'own', 'against', 'into', 'under', 'above', 'upon', 'among', 'together', 'while', 'nor', 'could', \n",
    "    'would', 'should', 'might', 'must', 'very', 'without', 'within', 'through', 'around', 'towards', \n",
    "    'onto', 'yet', 'ever', 'always', 'often', 'almost', 'even', 'especially', 'mostly'\n",
    "}\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:27.722342Z",
     "start_time": "2024-12-08T23:40:23.844126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[decrease, mam, child, admission, &lt;num&gt;, &lt;date...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[&lt;num&gt;, fear, ebola, lead, attack, health, wor...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wheat, staple, food, most, afghan, comprise, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[receive, serious, allegation, two, lna, fight...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[somali, &lt;num&gt;, &lt;num&gt;, woredas, hotspot, &lt;num&gt;...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  [decrease, mam, child, admission, <num>, <date...      8\n",
       "1  [<num>, fear, ebola, lead, attack, health, wor...      9\n",
       "2  [wheat, staple, food, most, afghan, comprise, ...      3\n",
       "3  [receive, serious, allegation, two, lna, fight...      9\n",
       "4  [somali, <num>, <num>, woredas, hotspot, <num>...      8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if WIN_PATHS_ENABLED:\n",
    "    test = pd.read_csv(r\"C:\\Users\\azatv\\Jupyter\\JupyterProjects\\NLP\\nlp2024_25_data\\nlp2023_24_data\\thedeep.subset.test.txt\", sep=\",\", header=None, names=['ID', 'Text', 'Label'], quoting=1, encoding='utf-8')\n",
    "else:\n",
    "    test = pd.read_csv(r\"/Users/bayve/Desktop/JKU/NLP/Assignments/NLP/nlp2024_25_data/nlp2023_24_data/thedeep.subset.test.txt\", sep=\",\", header=None, names=['ID', 'Text', 'Label'], quoting=1, encoding='utf-8')\n",
    "\n",
    "test = test.drop('ID', axis=1)\n",
    "\n",
    "test = preprocessing(test)\n",
    "\n",
    "print(\"Test Data:\")\n",
    "display(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:27.763131Z",
     "start_time": "2024-12-08T23:40:27.722933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "4     635\n",
      "9     615\n",
      "3     405\n",
      "10    180\n",
      "11    172\n",
      "2     123\n",
      "5     121\n",
      "8     112\n",
      "1     107\n",
      "0      45\n",
      "7      45\n",
      "6      35\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "group_per_label = dict()\n",
    "labels = np.sort(test[\"Label\"].unique())\n",
    "label_counts = test[\"Label\"].value_counts()\n",
    "for label in labels:\n",
    "    group_per_label[label] = []\n",
    "\n",
    "for idx, row in test.iterrows():\n",
    "    label = row[\"Label\"]\n",
    "    group_per_label[label].append(row)\n",
    "\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:27.767153Z",
     "start_time": "2024-12-08T23:40:27.763781Z"
    }
   },
   "outputs": [],
   "source": [
    "rows_with_specific_label = list()\n",
    "for i in labels:\n",
    "    rows_with_specific_label.append(test[test[\"Label\"] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:27.800864Z",
     "start_time": "2024-12-08T23:40:27.767653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats of the dictionary before reduction:\n",
      "Mean (excluding <num> and <date>): 2.087216248506571\n",
      "Max (excluding <num> and <date>): 26\n",
      "Min (excluding <num> and <date>): 1\n",
      "Standard Deviation (excluding <num> and <date>): 2.4068384289869833\n",
      "Stats of the dictionary after reduction:\n",
      "Mean (excluding <num> and <date>): 4.003300330033003\n",
      "Max (excluding <num> and <date>): 26\n",
      "Min (excluding <num> and <date>): 2\n",
      "Standard Deviation (excluding <num> and <date>): 3.201173825379828\n",
      "Vocabulary Size: 305\n",
      "TF-IDF Test Sparsity Rate: 96.46%\n"
     ]
    }
   ],
   "source": [
    "vocab_test = full_vocabluary(rows_with_specific_label[0])\n",
    "\n",
    "mean_1, max_count_1, min_count_1, std_dev_1 = token_statistics(vocab_test)\n",
    "print(\"Stats of the dictionary before reduction:\")\n",
    "print(f\"Mean (excluding <num> and <date>): {mean_1}\")\n",
    "print(f\"Max (excluding <num> and <date>): {max_count_1}\")\n",
    "print(f\"Min (excluding <num> and <date>): {min_count_1}\")\n",
    "print(f\"Standard Deviation (excluding <num> and <date>): {std_dev_1}\")\n",
    "\n",
    "min_freq = mean_1/2\n",
    "\n",
    "vocab_test_copy = vocab_test\n",
    "test_filtered_vocab = filter_vocab(vocab_test_copy, min_freq)\n",
    "\n",
    "test_data = replace_with_oov_avoid(test, test_filtered_vocab)\n",
    "\n",
    "mean_2, max_count_2, min_count_2, std_dev_2 = token_statistics_after(test_filtered_vocab)\n",
    "\n",
    "print(\"Stats of the dictionary after reduction:\")\n",
    "print(f\"Mean (excluding <num> and <date>): {mean_2}\")\n",
    "print(f\"Max (excluding <num> and <date>): {max_count_2}\")\n",
    "print(f\"Min (excluding <num> and <date>): {min_count_2}\")\n",
    "print(f\"Standard Deviation (excluding <num> and <date>): {std_dev_2}\")\n",
    "\n",
    "vocab_list = sorted(test_filtered_vocab.keys())\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocab_list)}\n",
    "vocab_size = len(vocab_list)\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "\n",
    "df = calculate_document_frequencies(test_data, word_to_index)\n",
    "N = len(test_data) \n",
    "\n",
    "tfidf_test_vectors = compute_tfidf_vectors(test_data, word_to_index, df, N)\n",
    "\n",
    "tfidf_test_sparsity = calculate_sparsity(tfidf_test_vectors)\n",
    "\n",
    "print(f\"TF-IDF Test Sparsity Rate: {tfidf_test_sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:27.861295Z",
     "start_time": "2024-12-08T23:40:27.801547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word contributions for category '0':\n",
      "crop: 0.014130434782608696\n",
      "season: 0.010869565217391304\n",
      "area: 0.010326086956521738\n",
      "farmer: 0.009782608695652175\n",
      "agriculture: 0.008152173913043478\n",
      "year: 0.007065217391304348\n",
      "rain: 0.007065217391304348\n",
      "report: 0.006521739130434782\n",
      "production: 0.006521739130434782\n",
      "price: 0.005978260869565218\n",
      "\n",
      "\n",
      "Word contributions for category '1':\n",
      "people: 0.01221443112418005\n",
      "need: 0.011309658448314861\n",
      "area: 0.009047726758651889\n",
      "humanitarian: 0.0081429540827867\n",
      "assistance: 0.006785795068988917\n",
      "displace: 0.006333408731056322\n",
      "say: 0.006107215562090025\n",
      "food: 0.006107215562090025\n",
      "water: 0.005654829224157431\n",
      "child: 0.0054286360551911335\n",
      "\n",
      "\n",
      "Word contributions for category '2':\n",
      "school: 0.04489059327769005\n",
      "child: 0.02278366794495827\n",
      "education: 0.018046469659372885\n",
      "teacher: 0.009925558312655087\n",
      "year: 0.008120911346717798\n",
      "student: 0.005865102639296188\n",
      "refugee: 0.005639521768554027\n",
      "need: 0.005639521768554027\n",
      "area: 0.0054139408978118655\n",
      "due: 0.004962779156327543\n",
      "\n",
      "\n",
      "Word contributions for category '3':\n",
      "food: 0.0318270917156711\n",
      "price: 0.012947487877849995\n",
      "area: 0.010161972557515733\n",
      "household: 0.009233467450737646\n",
      "people: 0.008459713195089239\n",
      "ipc: 0.008356545961002786\n",
      "phase: 0.008201795109873105\n",
      "average: 0.007170122769008563\n",
      "increase: 0.007015371917878882\n",
      "season: 0.006963788300835654\n",
      "\n",
      "\n",
      "Word contributions for category '4':\n",
      "case: 0.029847376501399802\n",
      "health: 0.018874740359432856\n",
      "report: 0.01742978415966766\n",
      "cholera: 0.008443962792377855\n",
      "outbreak: 0.007631174930009934\n",
      "people: 0.0069990065926126615\n",
      "death: 0.006953851711369999\n",
      "hospital: 0.005689515036575454\n",
      "suspect: 0.005644360155332791\n",
      "state: 0.0053734308678768175\n",
      "\n",
      "\n",
      "Word contributions for category '5':\n",
      "area: 0.008187400500341141\n",
      "say: 0.00727768933363657\n",
      "people: 0.006595405958608142\n",
      "report: 0.006367978166931999\n",
      "livestock: 0.005913122583579713\n",
      "food: 0.005913122583579713\n",
      "household: 0.005003411416875142\n",
      "price: 0.0047759836251989995\n",
      "livelihood: 0.0047759836251989995\n",
      "farmer: 0.004548555833522857\n",
      "\n",
      "\n",
      "Word contributions for category '6':\n",
      "humanitarian: 0.019114688128772636\n",
      "area: 0.013078470824949699\n",
      "road: 0.012072434607645875\n",
      "food: 0.009054325955734407\n",
      "affect: 0.009054325955734407\n",
      "port: 0.007042253521126761\n",
      "access: 0.006036217303822937\n",
      "report: 0.006036217303822937\n",
      "supply: 0.006036217303822937\n",
      "population: 0.006036217303822937\n",
      "\n",
      "\n",
      "Word contributions for category '7':\n",
      "fuel: 0.015693659761456372\n",
      "power: 0.015065913370998116\n",
      "electricity: 0.013182674199623353\n",
      "need: 0.011299435028248588\n",
      "supply: 0.008788449466415568\n",
      "report: 0.008788449466415568\n",
      "item: 0.007532956685499058\n",
      "people: 0.007532956685499058\n",
      "gaza: 0.006277463904582548\n",
      "say: 0.006277463904582548\n",
      "\n",
      "\n",
      "Word contributions for category '8':\n",
      "child: 0.033179457587997695\n",
      "malnutrition: 0.027409117137911138\n",
      "acute: 0.019619157530294286\n",
      "nutrition: 0.013271783035199077\n",
      "sam: 0.012694748990190421\n",
      "rate: 0.008366993652625505\n",
      "food: 0.0075014425851125215\n",
      "severe: 0.0075014425851125215\n",
      "region: 0.007212925562608194\n",
      "high: 0.006347374495095211\n",
      "\n",
      "\n",
      "Word contributions for category '9':\n",
      "child: 0.009134580391585996\n",
      "say: 0.008370332629740155\n",
      "report: 0.008006405124099279\n",
      "force: 0.006223160346458986\n",
      "woman: 0.00615037484533081\n",
      "people: 0.005968411092510372\n",
      "include: 0.005604483586869495\n",
      "right: 0.0049858068272800055\n",
      "area: 0.004876628575587743\n",
      "group: 0.004294344566562341\n",
      "\n",
      "\n",
      "Word contributions for category '10':\n",
      "people: 0.015410716810405768\n",
      "shelter: 0.012583062349780856\n",
      "house: 0.010320938781280927\n",
      "area: 0.008624346104905981\n",
      "affect: 0.00834158065884349\n",
      "flood: 0.007917432489749753\n",
      "damage: 0.006786370705499788\n",
      "camp: 0.006362222536406051\n",
      "family: 0.006362222536406051\n",
      "need: 0.0055139261982185776\n",
      "\n",
      "\n",
      "Word contributions for category '11':\n",
      "water: 0.052216748768472904\n",
      "need: 0.010133708655876143\n",
      "wash: 0.009852216748768473\n",
      "supply: 0.009429978888106967\n",
      "area: 0.007881773399014778\n",
      "access: 0.007741027445460943\n",
      "people: 0.0076002814919071075\n",
      "source: 0.007037297677691766\n",
      "facility: 0.005770584095707248\n",
      "camp: 0.005629838142153413\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "word_contributions_list = list()\n",
    "most_pop_words_from_each_category = list()\n",
    "all_words_list = list()\n",
    "for class_rows in rows_with_specific_label:\n",
    "    word_contributions = analyze_word_contributions_by_category(class_rows, \"Label\", \"Text\")\n",
    "    \n",
    "    filtered_word_contributions = {\n",
    "        category: {\n",
    "            word: count for word, count in word_counts.items()\n",
    "            if len(word) > 1 and word not in stop_words and word not in {\"<num>\", \"<date>\"}\n",
    "        }\n",
    "        for category, word_counts in word_contributions.items()\n",
    "    }\n",
    "    \n",
    "    if all(len(words) == 0 for words in filtered_word_contributions.values()):\n",
    "        continue\n",
    "    \n",
    "    for category, word_counts in filtered_word_contributions.items():\n",
    "        print(f\"Word contributions for category '{category}':\")\n",
    "        \n",
    "        sorted_words = sorted(word_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "        for word, count in sorted_words:\n",
    "            all_words_list.append(word)\n",
    "        top_words_dict = sorted_words[:10]\n",
    "        top_words_string = list()\n",
    "        for word, count in top_words_dict:\n",
    "            top_words_string.append(word)\n",
    "            print(f\"{word}: {count}\")\n",
    "        \n",
    "        print(\"\\n\")\n",
    "    most_pop_words_from_each_category.append(top_words_string)\n",
    "    word_contributions_list.append(filtered_word_contributions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:27.866619Z",
     "start_time": "2024-12-08T23:40:27.863428Z"
    }
   },
   "outputs": [],
   "source": [
    "all_words_list = list(set(all_words_list))\n",
    "random_six_words = random.choices(all_words_list, k=5)\n",
    "most_pop_words = most_pop_words_from_each_category[0][:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:27.868880Z",
     "start_time": "2024-12-08T23:40:27.867229Z"
    }
   },
   "outputs": [],
   "source": [
    "if(PLOTS_SHOW):\n",
    "    for item in word_contributions_list:\n",
    "        for category in item.keys():\n",
    "            plot_word_contributions(item, category, top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:36.645658Z",
     "start_time": "2024-12-08T23:40:27.869320Z"
    }
   },
   "outputs": [],
   "source": [
    "if(WIN_PATHS_ENABLED):\n",
    "    model_path = \"GoogleNews-vectors-negative300.bin\" \n",
    "else:\n",
    "    model_path = \"/Users/bayve/Desktop/JKU/NLP/word2vec/GoogleNews-vectors-negative300.bin\" \n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:36.649278Z",
     "start_time": "2024-12-08T23:40:36.646536Z"
    }
   },
   "outputs": [],
   "source": [
    "source_words = [word for word in most_pop_words if word in model]\n",
    "target_words = [word for word in random_six_words if word in model]\n",
    "\n",
    "if not source_words or not target_words:\n",
    "    raise ValueError(\"No valid words found in the model for comparison.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T00:02:40.340085Z",
     "start_time": "2024-12-09T00:02:40.338026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'dog' and 'car': 0.3100\n"
     ]
    }
   ],
   "source": [
    "#Cosine similarity test\n",
    "word1 = 'dog'\n",
    "word2 = 'car'\n",
    "similarity = cosine_similarity(model[word1], model[word2])\n",
    "print(f\"Cosine similarity between '{word1}' and '{word2}': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:48.430466Z",
     "start_time": "2024-12-08T23:40:36.649948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity\n",
      "\n",
      "Source Word: crop\n",
      "Top 10 Neighbors:\n",
      "  prepositioning: 0.1311\n",
      "  salman: 0.0575\n",
      "  clean: 0.0312\n",
      "  nursing: 0.0292\n",
      "----------------------------------------\n",
      "Source Word: season\n",
      "Top 10 Neighbors:\n",
      "  nursing: 0.1330\n",
      "  prepositioning: 0.0619\n",
      "  clean: 0.0398\n",
      "  salman: 0.0246\n",
      "----------------------------------------\n",
      "Source Word: area\n",
      "Top 10 Neighbors:\n",
      "  prepositioning: 0.1515\n",
      "  clean: 0.1007\n",
      "  nursing: 0.0795\n",
      "  salman: 0.0182\n",
      "----------------------------------------\n",
      "Source Word: farmer\n",
      "Top 10 Neighbors:\n",
      "  salman: 0.1126\n",
      "  nursing: 0.0469\n",
      "  clean: 0.0408\n",
      "  prepositioning: 0.0178\n",
      "----------------------------------------\n",
      "Source Word: agriculture\n",
      "Top 10 Neighbors:\n",
      "  nursing: 0.1570\n",
      "  clean: 0.1525\n",
      "  prepositioning: 0.1439\n",
      "  salman: 0.0218\n",
      "----------------------------------------\n",
      "Dot product similarity\n",
      "\n",
      "Source Word: crop\n",
      "Top 10 Neighbors:\n",
      "  prepositioning: 1.3345\n",
      "  salman: 0.4135\n",
      "  nursing: 0.2783\n",
      "  clean: 0.2635\n",
      "----------------------------------------\n",
      "Source Word: season\n",
      "Top 10 Neighbors:\n",
      "  nursing: 1.0236\n",
      "  prepositioning: 0.5095\n",
      "  clean: 0.2716\n",
      "  salman: 0.1429\n",
      "----------------------------------------\n",
      "Source Word: area\n",
      "Top 10 Neighbors:\n",
      "  prepositioning: 0.9959\n",
      "  clean: 0.5498\n",
      "  nursing: 0.4887\n",
      "  salman: 0.0844\n",
      "----------------------------------------\n",
      "Source Word: farmer\n",
      "Top 10 Neighbors:\n",
      "  salman: 0.8506\n",
      "  nursing: 0.4694\n",
      "  clean: 0.3624\n",
      "  prepositioning: 0.1898\n",
      "----------------------------------------\n",
      "Source Word: agriculture\n",
      "Top 10 Neighbors:\n",
      "  nursing: 1.4339\n",
      "  prepositioning: 1.4051\n",
      "  clean: 1.2367\n",
      "  salman: 0.1505\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test nearest neighbours\n",
    "#Cosine similarity\n",
    "similarities = calculate_nearest_neighbours(source_words, target_words, model, 10, True, False)  \n",
    "# Display the results\n",
    "print('Cosine similarity\\n')\n",
    "for source_word, neighbors in similarities.items():\n",
    "    print(f\"Source Word: {source_word}\")\n",
    "    print(\"Top 10 Neighbors:\")\n",
    "    for neighbor_word, similarity_score in neighbors.items():\n",
    "        print(f\"  {neighbor_word}: {similarity_score:.4f}\")\n",
    "    print(\"-\" * 40)  # Separator for better readability\n",
    "#Dot product similarity\n",
    "similarities = calculate_nearest_neighbours(source_words, target_words, model, 10, False, True)\n",
    "# Display the results\n",
    "print('Dot product similarity\\n')\n",
    "for source_word, neighbors in similarities.items():\n",
    "    print(f\"Source Word: {source_word}\")\n",
    "    print(\"Top 10 Neighbors:\")\n",
    "    for neighbor_word, similarity_score in neighbors.items():\n",
    "        print(f\"  {neighbor_word}: {similarity_score:.4f}\")\n",
    "    print(\"-\" * 40)  # Separator for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:48.440909Z",
     "start_time": "2024-12-08T23:40:48.439801Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-taskB\"></a><h2 style=\"color:rgb(0,120,170)\">Task B: Document Classification with WE (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This task follows the same instruction for document classification as provided in Assignment 1. You are indeed free to reuse any part of your code in Assignment 1 for this task. In Assignment 1, the representation of each document was created using a bag of words representation followed by dimensionality reduction. In this task, the document representations are created from the pre-trained word embeddings.\n",
    "\n",
    "**Map word embeddings to dictionary words (5 points).** For every word in the dictionary (as discussed and created in Assignment 1), fetch the corresponding word embedding from the pre-trained model. If no embedding is found, initialize the corresponding word embedding randomly.\n",
    "\n",
    "**Document embedding as the average of word embeddings (5 points).** Using the word embeddings, the representation of each document is defined as the *mean of the vectors of each document's words*. In particular, given the document $d$, consisting of words $\\left[ v_1, v_2, ..., v_{|d|} \\right]$, the document representation $\\mathbf{e}_d$ is defined as:\n",
    "\n",
    "$\\mathbf{e}_d = \\frac{1}{|d|}\\sum_{i=1}^{|d|}{\\mathbf{e}_{v_i}}$\n",
    "\n",
    "where $\\mathbf{e}_{v}$ is the vector of the word $v$, and $|d|$ is the length of the document.\n",
    "\n",
    "**Classification and evaluation (5 points)** Using these new document representations, apply <ins>three classification algorithms</ins> and report the evaluation results (based on accuracy metric) on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:48.444819Z",
     "start_time": "2024-12-08T23:40:48.443289Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "if WIN_PATHS_ENABLED:\n",
    "    train = pd.read_csv(r\"C:\\Users\\azatv\\Jupyter\\JupyterProjects\\NLP\\nlp2024_25_data\\nlp2023_24_data\\thedeep.subset.train.txt\", sep=\",\", header=None, names=['ID', 'Text', 'Label'], quoting=1, encoding='utf-8')\n",
    "    validation = pd.read_csv(r\"C:\\Users\\azatv\\Jupyter\\JupyterProjects\\NLP\\nlp2024_25_data\\nlp2023_24_data\\thedeep.subset.validation.txt\", sep=\",\", header=None, names=['ID', 'Text', 'Label'], quoting=1, encoding='utf-8')\n",
    "    test = pd.read_csv(r\"C:\\Users\\azatv\\Jupyter\\JupyterProjects\\NLP\\nlp2024_25_data\\nlp2023_24_data\\thedeep.subset.test.txt\", sep=\",\", header=None, names=['ID', 'Text', 'Label'], quoting=1, encoding='utf-8')\n",
    "else:\n",
    "    train = pd.read_csv(r\"mac_path\\thedeep.subset.train.txt\", sep=\",\", header=None, names=['ID', 'Text', 'Label'], quoting=1, encoding='utf-8')\n",
    "    validation = pd.read_csv(r\"mac_path\\thedeep.subset.validation.txt\", sep=\",\", header=None, names=['ID', 'Text', 'Label'], quoting=1, encoding='utf-8')\n",
    "    test = pd.read_csv(r\"mac_path\\thedeep.subset.test.txt\", sep=\",\", header=None, names=['ID', 'Text', 'Label'], quoting=1, encoding='utf-8')\n",
    "\n",
    "train = preprocessing(train)\n",
    "validation = preprocessing(validation)\n",
    "test = preprocessing(test)\n",
    "\n",
    "vocab = create_vocab(train)\n",
    "word_embeddings = map_word_embeddings(vocab, model)\n",
    "\n",
    "train_embeddings = compute_document_embeddings(train, word_embeddings)\n",
    "validation_embeddings = compute_document_embeddings(validation, word_embeddings)\n",
    "test_embeddings = compute_document_embeddings(test, word_embeddings)\n",
    "\n",
    "y_train = train[\"Label\"]\n",
    "y_validation = validation[\"Label\"]\n",
    "y_test = test[\"Label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Model  Validation Accuracy  Test Accuracy\n",
      "0       Logistic Regression - C=0.01             0.561633       0.569171\n",
      "1        Logistic Regression - C=0.1             0.709938       0.714066\n",
      "2          Logistic Regression - C=1             0.766564       0.774566\n",
      "3         Logistic Regression - C=10             0.764638       0.780347\n",
      "4    Random Forest - n_estimators=50             0.705316       0.699037\n",
      "5   Random Forest - n_estimators=100             0.707627       0.711368\n",
      "6   Random Forest - n_estimators=150             0.716102       0.714451\n",
      "7                       SVM - C=0.01             0.554700       0.560308\n",
      "8                        SVM - C=0.1             0.724576       0.729480\n",
      "9                          SVM - C=1             0.786595       0.786513\n",
      "10                        SVM - C=10             0.785439       0.790366\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary to store results dynamically\n",
    "results = []\n",
    "\n",
    "# Logistic Regression\n",
    "for C in [0.01, 0.1, 1, 10]:\n",
    "    lr = LogisticRegression(max_iter=1000, C=C)\n",
    "    lr.fit(train_embeddings, y_train)\n",
    "    \n",
    "    validation_preds = lr.predict(validation_embeddings)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_preds)\n",
    "    \n",
    "    test_preds = lr.predict(test_embeddings)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": f\"Logistic Regression - C={C}\",\n",
    "        \"Validation Accuracy\": validation_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy\n",
    "    })\n",
    "\n",
    "# Random Forest\n",
    "for n_estimators in [50, 100, 150]:\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    rf.fit(train_embeddings, y_train)\n",
    "    \n",
    "    validation_preds = rf.predict(validation_embeddings)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_preds)\n",
    "    \n",
    "    test_preds = rf.predict(test_embeddings)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": f\"Random Forest - n_estimators={n_estimators}\",\n",
    "        \"Validation Accuracy\": validation_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy\n",
    "    })\n",
    "\n",
    "# SVM\n",
    "for C in [0.01, 0.1, 1, 10]:\n",
    "    svm = SVC(C=C)\n",
    "    svm.fit(train_embeddings, y_train)\n",
    "    \n",
    "    validation_preds = svm.predict(validation_embeddings)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_preds)\n",
    "    \n",
    "    test_preds = svm.predict(test_embeddings)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": f\"SVM - C={C}\",\n",
    "        \"Validation Accuracy\": validation_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS FROM ASS 1\n",
    "# Model  Validation Accuracy  Test Accuracy\n",
    "# 0                Dummy Baseline             0.256163       0.244701\n",
    "# 1      Logistic Regression (TF)             0.779661       0.768015\n",
    "# 2  Logistic Regression (TF-IDF)             0.681048       0.737958\n",
    "# 3            Random Forest (TF)             0.761171       0.759538\n",
    "# 4        Random Forest (TF-IDF)             0.569337       0.759923"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-taskC\"></a><h2 style=\"color:rgb(0,120,170)\">Task C: Classification with sent2vec Document Embeddings (2 extra point)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sent2vec [1] suggests another unsupervised approach to creating document embeddings from the underlying word embeddings. First, using the provided code in the paper, train a sendtvec model on the training set to create document embeddings. Then, repeat Task B while using the document embeddings provided by sent2vec. Similar to Task 2, conduct the classification experiments and report evaluation results.\n",
    "\n",
    "[1] M. Pagliardini, P. Gupta, and M. Jaggi. Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features. In Proceedings of the conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2018.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:40:48.450015Z",
     "start_time": "2024-12-08T23:40:48.448828Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
